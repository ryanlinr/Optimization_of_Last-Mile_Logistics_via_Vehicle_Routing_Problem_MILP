{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install ortools"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"UEJEeDpAiMj2","executionInfo":{"status":"ok","timestamp":1765833756913,"user_tz":480,"elapsed":13764,"user":{"displayName":"Oyun Erdene Adilbish","userId":"14736631648265701628"}},"outputId":"241fb3a7-d4bd-4e65-b6eb-ea1a7718c503"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ortools\n","  Downloading ortools-9.14.6206-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n","Collecting absl-py>=2.0.0 (from ortools)\n","  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from ortools) (2.0.2)\n","Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ortools) (2.2.2)\n","Collecting protobuf<6.32,>=6.31.1 (from ortools)\n","  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from ortools) (4.15.0)\n","Requirement already satisfied: immutabledict>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from ortools) (4.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->ortools) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->ortools) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->ortools) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->ortools) (1.17.0)\n","Downloading ortools-9.14.6206-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (27.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.7/27.7 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.1/321.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: protobuf, absl-py, ortools\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 5.29.5\n","    Uninstalling protobuf-5.29.5:\n","      Successfully uninstalled protobuf-5.29.5\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 1.4.0\n","    Uninstalling absl-py-1.4.0:\n","      Successfully uninstalled absl-py-1.4.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.31.1 which is incompatible.\n","tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.31.1 which is incompatible.\n","google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.31.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed absl-py-2.3.1 ortools-9.14.6206 protobuf-6.31.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]},"id":"7fcbda15670f4377a8a0a203d3dedfeb"}},"metadata":{}}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"LlHg2hXQh8_5","executionInfo":{"status":"error","timestamp":1765833757733,"user_tz":480,"elapsed":807,"user":{"displayName":"Oyun Erdene Adilbish","userId":"14736631648265701628"}},"outputId":"02f12ce1-61dd-40cd-a0bc-4a23c20341af","colab":{"base_uri":"https://localhost:8080/","height":0}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'orders_day1.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3546712923.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# --- 1. Load DataFrames ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf_orders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'orders_day1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdf_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'distance_day1.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdf_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time_day1.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'orders_day1.csv'"]}],"source":["# %% Method 2\n","\n","import pandas as pd\n","from ortools.constraint_solver import routing_enums_pb2\n","from ortools.constraint_solver import pywrapcp\n","import numpy as np\n","\n","# --- 1. Load DataFrames ---\n","df_orders = pd.read_csv('orders_day1.csv')\n","df_distance = pd.read_csv('distance_day1.csv', index_col=0)\n","df_time = pd.read_csv('time_day1.csv', index_col=0)\n","\n","# --- PARAMETERS BASED ON MIP FORMULATION ---\n","# Alpha (α): Coefficient to penalize the number of vehicles. Must be large to prioritize\n","# vehicle count minimization over total travel time minimization.\n","ALPHA_VEHICLE_PENALTY = 200\n","\n","# Physical Fleet Specifications (for sanity checks and fleet sizing)\n","PHYSICAL_FLEET_SPECS = {\n","    'weight': 2000,  # Max weight capacity of each truck\n","    'volume': 1000   # Max volume capacity of each truck\n","}\n","\n","# Buffer time to ensure depot is open when vehicles return\n","BUFFER_RETURN_TIME = 200\n","\n","# Extra vehicles to add beyond theoretical minimum\n","ROUTING_BUFFER = 5\n","\n","# ----------------------------------------------------------------------\n","# --- 2. Data Structure Preparation for OR-Tools ---\n","# ----------------------------------------------------------------------\n","\n","import math\n","\n","def create_data_model_smart(orders_df, distance_df, time_df, physical_fleet_specs={}):\n","    \"\"\"\n","    Initializes VRP data dynamically based on input statistics to ensure feasibility.\n","\n","    physical_fleet_specs: dict containing 'weight_limit', 'volume_limit' of your REAL trucks.\n","    \"\"\"\n","    data = {}\n","\n","    # --- 1. Data Cleaning (Keep existing logic) ---\n","    distance_df.dropna(how='all', axis=0, inplace=True)\n","    distance_df.dropna(how='all', axis=1, inplace=True)\n","    time_df.dropna(how='all', axis=0, inplace=True)\n","    time_df.dropna(how='all', axis=1, inplace=True)\n","\n","    data['distance_matrix'] = distance_df.values.astype(int).tolist()\n","    data['time_matrix'] = time_df.values.astype(int).tolist()\n","\n","    # --- 2. Smart Time Window Parsing ---\n","    # Parse actual windows first to find the \"Horizon\" (Latest possible deadline)\n","    parsed_windows = []\n","    max_deadline_in_data = 0\n","\n","    # Depot is always (0,0) or (0, Open_Duration)\n","    # Let's assume Depot is open as long as the latest customer needs.\n","    parsed_windows.append((0, 0))\n","\n","    for tw_str in orders_df['TIME WINDOW']:\n","        # Parse the string \"(900, 1200)\" -> 900, 1200\n","        clean_str = tw_str.strip('()')\n","        if ',' in clean_str:\n","            parts = clean_str.split(',')\n","            start = int(parts[0])\n","            end = int(parts[1])\n","            parsed_windows.append((start, end))\n","            # Track the latest time anyone needs service\n","            if end > max_deadline_in_data:\n","                max_deadline_in_data = end\n","        else:\n","            # Fallback for bad data\n","            parsed_windows.append((0, 10000)) # Default fallback\n","\n","    # Update Depot's window to extend to the latest deadline (plus return trip buffer)\n","    # This prevents the \"Depot closed before driver returns\" error.\n","    # approx time to drive back to depot after last delivery\n","    horizon = max_deadline_in_data + BUFFER_RETURN_TIME\n","    parsed_windows[0] = (0, horizon)\n","\n","    data['time_windows'] = parsed_windows\n","    data['vehicle_max_travel_time'] = horizon # Set Horizon dynamically\n","\n","    # --- 3. Demand & Capacity Sanity Check ---\n","    data['weights'] = [0] + orders_df['WEIGHT'].round().astype(int).tolist()\n","\n","    # Notice: Multiplier is consistent (was 100 in your snippet, 1000 in previous. Check your data!)\n","    data['volumes'] = [0] + (orders_df['VOLUME'] * 100).round().astype(int).tolist()\n","\n","    # CONSTANTS (Physical limits of your trucks)\n","    TRUCK_W_CAP = physical_fleet_specs.get('weight', 2000)\n","    TRUCK_V_CAP = physical_fleet_specs.get('volume', 1000)\n","\n","    # Sanity Check: Does the biggest order fit in a truck?\n","    max_order_w = max(data['weights'])\n","    if max_order_w > TRUCK_W_CAP:\n","        raise ValueError(f\"CRITICAL ERROR: Order exists with weight {max_order_w}, but truck limit is {TRUCK_W_CAP}.\")\n","\n","    # --- 4. Smart Fleet Sizing (The Lower Bound Calculation) ---\n","    total_weight = sum(data['weights'])\n","    total_volume = sum(data['volumes'])\n","\n","    # Minimum trucks needed purely for capacity (Bin Packing Lower Bound)\n","    min_trucks_weight = math.ceil(total_weight / TRUCK_W_CAP)\n","    min_trucks_volume = math.ceil(total_volume / TRUCK_V_CAP)\n","\n","    theoretical_min_vehicles = max(min_trucks_weight, min_trucks_volume)\n","\n","    # Add a \"Routing Buffer\" (e.g., 20% or +2 trucks)\n","    # Vehicles can rarely be 100% full because they run out of Time or Distance first.\n","    recommended_fleet_size = int(theoretical_min_vehicles * 1.2) + ROUTING_BUFFER\n","\n","    print(f\"--- Initialization Report ---\")\n","    print(f\"Total Weight: {total_weight} | Max Truck W: {TRUCK_W_CAP} -> Min Trucks: {min_trucks_weight}\")\n","    print(f\"Total Volume: {total_volume} | Max Truck V: {TRUCK_V_CAP} -> Min Trucks: {min_trucks_volume}\")\n","    print(f\"Latest Deadline found: {max_deadline_in_data}\")\n","    print(f\"Setting Fleet Size to: {recommended_fleet_size} (Theoretical Min: {theoretical_min_vehicles})\")\n","\n","    data['num_vehicles'] = recommended_fleet_size\n","    data['vehicle_capacities_weight'] = [TRUCK_W_CAP] * data['num_vehicles']\n","    data['vehicle_capacities_volume'] = [TRUCK_V_CAP] * data['num_vehicles']\n","\n","    # --- 5. Other Data ---\n","    data['service_times'] = [0] + orders_df['SERVICE_TIME'].astype(int).tolist()\n","    data['depot'] = 0\n","    data['penalty'] = 100000 # Keep high\n","\n","    return data\n","\n","# ----------------------------------------------------------------------\n","# --- 3. Initialize Solver Model and Constraints ---\n","# ----------------------------------------------------------------------\n","\n","def print_solution(data, manager, routing, solution):\n","   \"\"\"Prints the solution found by the solver.\"\"\"\n","   total_distance = 0\n","   total_time_cost = 0 # Cost is now based on time, not distance\n","   total_time = 0\n","   time_dimension = routing.GetDimensionOrDie('Time')\n","\n","   # Calculate the total travel time for the objective reporting\n","   for vehicle_id in range(data['num_vehicles']):\n","       index = routing.Start(vehicle_id)\n","       if routing.IsEnd(solution.Value(routing.NextVar(index))):\n","           continue\n","\n","       while not routing.IsEnd(index):\n","           previous_index = index\n","           index = solution.Value(routing.NextVar(index))\n","\n","           # The actual total travel time component of the objective\n","           from_node = manager.IndexToNode(previous_index)\n","           to_node = manager.IndexToNode(index)\n","           # The cost being minimized is based on the time matrix\n","           total_time_cost += data['time_matrix'][from_node][to_node]\n","\n","   # Calculate objective based on MIP formulation: alpha * Yk + sum(tij * xijk)\n","   num_used_vehicles = len([v for v in range(data['num_vehicles']) if not routing.IsEnd(solution.Value(routing.NextVar(routing.Start(v))))])\n","   vehicle_penalty_component = num_used_vehicles * ALPHA_VEHICLE_PENALTY\n","\n","   # NOTE: The OR-Tools objective value here may include dropped node penalties,\n","   # but the custom calculation below reflects the MIP goal:\n","   mip_objective = vehicle_penalty_component + total_time_cost\n","\n","   print(f'OR-Tools Objective (Time Cost + Penalties): {solution.ObjectiveValue()}')\n","   print(f'MIP Objective (Alpha*Vehicles + Total Time): {mip_objective} ({num_used_vehicles} vehicles * {ALPHA_VEHICLE_PENALTY} + {total_time_cost})')\n","\n","   # Print routes (unchanged)\n","   for vehicle_id in range(data['num_vehicles']):\n","       index = routing.Start(vehicle_id)\n","       if routing.IsEnd(solution.Value(routing.NextVar(index))):\n","           continue\n","\n","       plan_output = f'Route for vehicle {vehicle_id} (Depot: 0):'\n","       route_distance = 0\n","\n","       while not routing.IsEnd(index):\n","           time_var = time_dimension.CumulVar(index)\n","           node_index = manager.IndexToNode(index)\n","\n","           previous_index = index\n","           index = solution.Value(routing.NextVar(index))\n","\n","           route_distance += routing.GetArcCostForVehicle(\n","               previous_index, index, vehicle_id\n","           )\n","\n","           plan_output += (\n","               f' {node_index} -> Time({solution.Min(time_var)})'\n","           )\n","\n","       time_var = time_dimension.CumulVar(index)\n","       plan_output += (\n","           f' {manager.IndexToNode(index)} -> Time({solution.Min(time_var)})'\n","       )\n","       plan_output += f'\\n  Route Distance: {route_distance}'\n","       plan_output += f'\\n  Route End Time: {solution.Min(time_var)}'\n","\n","       print(plan_output)\n","       total_distance += route_distance\n","       total_time = max(total_time, solution.Min(time_var))\n","\n","   print(f'\\nTotal distance of all used routes: {total_distance}')\n","   print(f'Max route end time: {total_time}')\n","   print(f'Total travel time cost: {total_time_cost} (The minimized sum component)')\n","\n","   # --- Report Dropped Nodes ---\n","   dropped_nodes = []\n","#    for node in range(1, len(data['distance_matrix'])):\n","#        if solution.Value(routing.NextVar(manager.NodeToIndex(node))) == manager.NodeToIndex(node):\n","#            dropped_nodes.append(node)\n","\n","   if dropped_nodes:\n","       print(f'\\n!!! WARNING: {len(dropped_nodes)} Nodes Were DROPPED (Unserved) !!!')\n","       print(f'Dropped Nodes (NODE_ID): {dropped_nodes}')\n","   else:\n","       print('\\nSUCCESS: All nodes were served.')\n","\n","\n","def solve_vrp():\n","   \"\"\"Entry point for the VRP solver with MIP objective.\"\"\"\n","   data = create_data_model_smart(df_orders, df_distance, df_time)\n","\n","   manager = pywrapcp.RoutingIndexManager(\n","       len(data['distance_matrix']), data['num_vehicles'], data['depot']\n","   )\n","\n","   routing = pywrapcp.RoutingModel(manager)\n","\n","   # --- A. Define Cost (Time - as per MIP Objective) ---\n","   def time_cost_callback(from_index, to_index):\n","       from_node = manager.IndexToNode(from_index)\n","       to_node = manager.IndexToNode(to_index)\n","       # The cost minimized is the travel time (t_ij)\n","       return data['time_matrix'][from_node][to_node]\n","\n","   transit_callback_index = routing.RegisterTransitCallback(time_cost_callback)\n","   routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n","\n","   # A.1. Set Objective to Minimize Time Cost (t_ij) AND Penalize Vehicles (alpha * y_k)\n","\n","   # Fixed cost (alpha * y_k): Apply a large penalty for using each vehicle\n","   for vehicle_id in range(data['num_vehicles']):\n","       routing.SetFixedCostOfVehicle(ALPHA_VEHICLE_PENALTY, vehicle_id)\n","\n","   # A.2. Add Dropped Node Penalty\n","   for node in range(1, len(data['distance_matrix'])):\n","       routing.AddDisjunction([manager.NodeToIndex(node)], data['penalty'])\n","\n","   # --- B. Add Capacity Constraints (Weight and Volume) ---\n","\n","   def add_capacity_dimension(capacity_name, capacities, demands):\n","       def demand_callback(index):\n","           node = manager.IndexToNode(index)\n","           return demands[node]\n","\n","       demand_callback_index = routing.RegisterUnaryTransitCallback(demand_callback)\n","\n","       # Capacity bounds are imposed at every node [cite: 87]\n","       routing.AddDimensionWithVehicleCapacity(\n","           demand_callback_index,\n","           0, # Slack\n","           capacities,\n","           True, # This dimension is cumulative\n","           capacity_name\n","       )\n","\n","   add_capacity_dimension('WeightCapacity', data['vehicle_capacities_weight'], data['weights'])\n","   add_capacity_dimension('VolumeCapacity', data['vehicle_capacities_volume'], data['volumes'])\n","\n","\n","   # --- C. Add Time Window Constraints ---\n","\n","   def time_callback(from_index, to_index):\n","       from_node = manager.IndexToNode(from_index)\n","       to_node = manager.IndexToNode(to_index)\n","       travel_time = data['time_matrix'][from_node][to_node]\n","       service_time = data['service_times'][from_node]\n","       # Time propagation: T_jk >= T_ik + s_i + t_ij [cite: 99]\n","       return travel_time + service_time\n","\n","   time_callback_index = routing.RegisterTransitCallback(time_callback)\n","\n","   # Time dimension: tracks T_ik (time vehicle k starts service at node i) [cite: 45]\n","   routing.AddDimension(\n","       time_callback_index,\n","       0,                             # slack_max (0 is fine here)\n","       data['vehicle_max_travel_time'], # Planning horizon H [cite: 28]\n","       False,\n","       'Time'\n","   )\n","   time_dimension = routing.GetDimensionOrDie('Time')\n","\n","   # Apply Time Windows [cite: 94]\n","   for node in range(len(data['time_windows'])):\n","       index = manager.NodeToIndex(node)\n","       start, end = data['time_windows'][node]\n","       time_dimension.CumulVar(index).SetRange(start, end)\n","\n","   # Apply Route Duration Constraint (limited by H) [cite: 104]\n","   for i in range(data['num_vehicles']):\n","       time_dimension.SetSpanUpperBoundForVehicle(\n","           data['vehicle_max_travel_time'],\n","           i\n","       )\n","\n","   # --- D. Set Search Parameters and Solve ---\n","   search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n","   search_parameters.first_solution_strategy = (\n","       routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC\n","   )\n","   search_parameters.local_search_metaheuristic = (\n","       routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH\n","   )\n","   search_parameters.time_limit.seconds = 120\n","\n","   # Solve the problem\n","   solution = routing.SolveWithParameters(search_parameters)\n","\n","   # --- E. Print Solution ---\n","   if solution:\n","       print_solution(data, manager, routing, solution)\n","   else:\n","       print('No solution found!')\n","\n","\n","# ----------------------------------------------------------------------\n","# --- EXECUTION ---\n","# ----------------------------------------------------------------------\n","\n","print(\"Running Vehicle Routing Problem Solver (MIP Objective: Minimize Vehicles, then Time)...\")\n","solve_vrp()"]}]}